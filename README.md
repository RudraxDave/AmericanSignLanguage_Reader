# AmericanSignLanguage_Reader
Project Data: The Dataset is 1.11 GB in Size. The images in the dataset are manually captured  and not computer-generated. The dataset linked above contains images from 29 classes (26  alphabets, SPACE, DELETE, and NOTHING). Each class contains 3000 images in the training set  and each image is a 200 x 200 RGB image.  The training data set contains 87,000 images, of which 26 are for the letters A-Z and 3 classes for  SPACE, DELETE, and NOTHING.  These 3 classes are very helpful in real-time applications and classification.  The test data set contains a mere 29 images, to encourage the use of real-world test images.>the test  set is very small. We plan to Experiment with different architectures and  hyperparameters. First, implement the CNN architecture described in the Models of [8] and apply our  training data to generate the classification of 26 Letters. Our goal is to map images from a particular  domain to a Letter that it means. We will be finetuning (transfer learning) existing models that  perform classification on RGB images. We will Look at the levels of RGB images in Particular  Centroidal Pixels and We can Classify from the Centre Which Shape is Defined. We are Planing to  Use RESNET - Residual Neural Networks or Similar to be able to argue and analyze the better  Accuracy between all of the Networks. 

(To be updated)
