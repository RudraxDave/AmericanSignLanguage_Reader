{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## ResNet-50 Convolutional Neural Network","metadata":{}},{"cell_type":"code","source":"#importing libraries\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torchvision\nfrom torchvision import datasets, transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import random_split,DataLoader\nimport torch.optim as optim","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-11T08:43:33.338083Z","iopub.execute_input":"2022-05-11T08:43:33.338340Z","iopub.status.idle":"2022-05-11T08:43:35.343901Z","shell.execute_reply.started":"2022-05-11T08:43:33.338311Z","shell.execute_reply":"2022-05-11T08:43:35.343053Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"**Data Loading - Train Set**","metadata":{}},{"cell_type":"code","source":"# setting file path\ntrain_filepath = \"../input/asl-alphabet/asl_alphabet_train/asl_alphabet_train\"","metadata":{"execution":{"iopub.status.busy":"2022-05-11T08:43:35.347001Z","iopub.execute_input":"2022-05-11T08:43:35.347596Z","iopub.status.idle":"2022-05-11T08:43:35.353508Z","shell.execute_reply.started":"2022-05-11T08:43:35.347565Z","shell.execute_reply":"2022-05-11T08:43:35.352812Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# defining transforms\ntrain_transforms = transforms.Compose([\n    transforms.ToTensor()\n])","metadata":{"execution":{"iopub.status.busy":"2022-05-11T08:43:35.354648Z","iopub.execute_input":"2022-05-11T08:43:35.355591Z","iopub.status.idle":"2022-05-11T08:43:35.362071Z","shell.execute_reply.started":"2022-05-11T08:43:35.355554Z","shell.execute_reply":"2022-05-11T08:43:35.361332Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#Data Loading \ntrain_dataset = datasets.ImageFolder(train_filepath, transform=train_transforms)\nprint(\"Train Dataset Info:\\n\")\ntrain_dataset","metadata":{"execution":{"iopub.status.busy":"2022-05-11T08:43:35.364110Z","iopub.execute_input":"2022-05-11T08:43:35.364953Z","iopub.status.idle":"2022-05-11T08:44:09.307879Z","shell.execute_reply.started":"2022-05-11T08:43:35.364818Z","shell.execute_reply":"2022-05-11T08:44:09.307173Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Train Dataset Info:\n\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Dataset ImageFolder\n    Number of datapoints: 87000\n    Root location: ../input/asl-alphabet/asl_alphabet_train/asl_alphabet_train\n    StandardTransform\nTransform: Compose(\n               ToTensor()\n           )"},"metadata":{}}]},{"cell_type":"code","source":"train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                               batch_size=100, \n                                               shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T08:44:09.309140Z","iopub.execute_input":"2022-05-11T08:44:09.309887Z","iopub.status.idle":"2022-05-11T08:44:09.314593Z","shell.execute_reply.started":"2022-05-11T08:44:09.309850Z","shell.execute_reply":"2022-05-11T08:44:09.313935Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_label = train_dataloader.dataset.classes\nprint(\"Labels :\\t\",train_label,\"\\nLength of the label list :\",len(train_label))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T08:44:09.315969Z","iopub.execute_input":"2022-05-11T08:44:09.316711Z","iopub.status.idle":"2022-05-11T08:44:09.325036Z","shell.execute_reply.started":"2022-05-11T08:44:09.316672Z","shell.execute_reply":"2022-05-11T08:44:09.324242Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Labels :\t ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space'] \nLength of the label list : 29\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Data Visualization","metadata":{}},{"cell_type":"code","source":"# Capturing labels\nlabel_list = []\nfor image,label in train_dataloader:\n    label_list.append(label.cpu().numpy()[0])","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:13:28.061376Z","iopub.execute_input":"2022-05-11T12:13:28.061662Z","iopub.status.idle":"2022-05-11T12:17:09.529062Z","shell.execute_reply.started":"2022-05-11T12:13:28.061630Z","shell.execute_reply":"2022-05-11T12:17:09.528319Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"#plotting Histogram\n\nplt.figure(figsize=(14,7))\nplt.style.use('seaborn-whitegrid')\nplt.hist(label_list, bins=90, facecolor = '#2ab0ff', edgecolor='#169acf', linewidth=0.5)\nplt.title('Train Data Spread') \nplt.xlabel('Labels') \nplt.ylabel('Frequency') \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:17:09.530524Z","iopub.execute_input":"2022-05-11T12:17:09.530771Z","iopub.status.idle":"2022-05-11T12:17:09.844148Z","shell.execute_reply.started":"2022-05-11T12:17:09.530737Z","shell.execute_reply":"2022-05-11T12:17:09.843488Z"},"trusted":true},"execution_count":98,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1008x504 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"# Checking the device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-05-11T08:44:09.335879Z","iopub.execute_input":"2022-05-11T08:44:09.337254Z","iopub.status.idle":"2022-05-11T08:44:09.412991Z","shell.execute_reply.started":"2022-05-11T08:44:09.337218Z","shell.execute_reply":"2022-05-11T08:44:09.412177Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"markdown","source":"**Loading ResNet-50 Model**","metadata":{}},{"cell_type":"code","source":"model_resnet = torchvision.models.resnet50(pretrained=True)\nmodel_resnet","metadata":{"execution":{"iopub.status.busy":"2022-05-11T08:44:09.414389Z","iopub.execute_input":"2022-05-11T08:44:09.414755Z","iopub.status.idle":"2022-05-11T08:44:15.584515Z","shell.execute_reply.started":"2022-05-11T08:44:09.414715Z","shell.execute_reply":"2022-05-11T08:44:15.583853Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/97.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adb50ae6fc204a3dbf0dc49712094eaa"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"for param in model_resnet.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2022-05-11T08:44:15.587039Z","iopub.execute_input":"2022-05-11T08:44:15.587437Z","iopub.status.idle":"2022-05-11T08:44:15.592417Z","shell.execute_reply.started":"2022-05-11T08:44:15.587402Z","shell.execute_reply":"2022-05-11T08:44:15.591668Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"in_features = model_resnet.fc.in_features\nmodel_resnet.fc = torch.nn.Linear(in_features, 29)\nmodel_resnet\n","metadata":{"execution":{"iopub.status.busy":"2022-05-11T08:44:15.595631Z","iopub.execute_input":"2022-05-11T08:44:15.596266Z","iopub.status.idle":"2022-05-11T08:44:15.608690Z","shell.execute_reply.started":"2022-05-11T08:44:15.596228Z","shell.execute_reply":"2022-05-11T08:44:15.607871Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=29, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2022-05-11T08:44:15.609955Z","iopub.execute_input":"2022-05-11T08:44:15.610243Z","iopub.status.idle":"2022-05-11T08:44:26.194200Z","shell.execute_reply.started":"2022-05-11T08:44:15.610209Z","shell.execute_reply":"2022-05-11T08:44:26.193348Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from torchsummary import summary\nmodel_resnet.to(device)\nsummary(model_resnet, (3, 200, 200), batch_size=100)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T08:44:26.196195Z","iopub.execute_input":"2022-05-11T08:44:26.196478Z","iopub.status.idle":"2022-05-11T08:44:35.950525Z","shell.execute_reply.started":"2022-05-11T08:44:26.196439Z","shell.execute_reply":"2022-05-11T08:44:35.949812Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1        [100, 64, 100, 100]           9,408\n       BatchNorm2d-2        [100, 64, 100, 100]             128\n              ReLU-3        [100, 64, 100, 100]               0\n         MaxPool2d-4          [100, 64, 50, 50]               0\n            Conv2d-5          [100, 64, 50, 50]           4,096\n       BatchNorm2d-6          [100, 64, 50, 50]             128\n              ReLU-7          [100, 64, 50, 50]               0\n            Conv2d-8          [100, 64, 50, 50]          36,864\n       BatchNorm2d-9          [100, 64, 50, 50]             128\n             ReLU-10          [100, 64, 50, 50]               0\n           Conv2d-11         [100, 256, 50, 50]          16,384\n      BatchNorm2d-12         [100, 256, 50, 50]             512\n           Conv2d-13         [100, 256, 50, 50]          16,384\n      BatchNorm2d-14         [100, 256, 50, 50]             512\n             ReLU-15         [100, 256, 50, 50]               0\n       Bottleneck-16         [100, 256, 50, 50]               0\n           Conv2d-17          [100, 64, 50, 50]          16,384\n      BatchNorm2d-18          [100, 64, 50, 50]             128\n             ReLU-19          [100, 64, 50, 50]               0\n           Conv2d-20          [100, 64, 50, 50]          36,864\n      BatchNorm2d-21          [100, 64, 50, 50]             128\n             ReLU-22          [100, 64, 50, 50]               0\n           Conv2d-23         [100, 256, 50, 50]          16,384\n      BatchNorm2d-24         [100, 256, 50, 50]             512\n             ReLU-25         [100, 256, 50, 50]               0\n       Bottleneck-26         [100, 256, 50, 50]               0\n           Conv2d-27          [100, 64, 50, 50]          16,384\n      BatchNorm2d-28          [100, 64, 50, 50]             128\n             ReLU-29          [100, 64, 50, 50]               0\n           Conv2d-30          [100, 64, 50, 50]          36,864\n      BatchNorm2d-31          [100, 64, 50, 50]             128\n             ReLU-32          [100, 64, 50, 50]               0\n           Conv2d-33         [100, 256, 50, 50]          16,384\n      BatchNorm2d-34         [100, 256, 50, 50]             512\n             ReLU-35         [100, 256, 50, 50]               0\n       Bottleneck-36         [100, 256, 50, 50]               0\n           Conv2d-37         [100, 128, 50, 50]          32,768\n      BatchNorm2d-38         [100, 128, 50, 50]             256\n             ReLU-39         [100, 128, 50, 50]               0\n           Conv2d-40         [100, 128, 25, 25]         147,456\n      BatchNorm2d-41         [100, 128, 25, 25]             256\n             ReLU-42         [100, 128, 25, 25]               0\n           Conv2d-43         [100, 512, 25, 25]          65,536\n      BatchNorm2d-44         [100, 512, 25, 25]           1,024\n           Conv2d-45         [100, 512, 25, 25]         131,072\n      BatchNorm2d-46         [100, 512, 25, 25]           1,024\n             ReLU-47         [100, 512, 25, 25]               0\n       Bottleneck-48         [100, 512, 25, 25]               0\n           Conv2d-49         [100, 128, 25, 25]          65,536\n      BatchNorm2d-50         [100, 128, 25, 25]             256\n             ReLU-51         [100, 128, 25, 25]               0\n           Conv2d-52         [100, 128, 25, 25]         147,456\n      BatchNorm2d-53         [100, 128, 25, 25]             256\n             ReLU-54         [100, 128, 25, 25]               0\n           Conv2d-55         [100, 512, 25, 25]          65,536\n      BatchNorm2d-56         [100, 512, 25, 25]           1,024\n             ReLU-57         [100, 512, 25, 25]               0\n       Bottleneck-58         [100, 512, 25, 25]               0\n           Conv2d-59         [100, 128, 25, 25]          65,536\n      BatchNorm2d-60         [100, 128, 25, 25]             256\n             ReLU-61         [100, 128, 25, 25]               0\n           Conv2d-62         [100, 128, 25, 25]         147,456\n      BatchNorm2d-63         [100, 128, 25, 25]             256\n             ReLU-64         [100, 128, 25, 25]               0\n           Conv2d-65         [100, 512, 25, 25]          65,536\n      BatchNorm2d-66         [100, 512, 25, 25]           1,024\n             ReLU-67         [100, 512, 25, 25]               0\n       Bottleneck-68         [100, 512, 25, 25]               0\n           Conv2d-69         [100, 128, 25, 25]          65,536\n      BatchNorm2d-70         [100, 128, 25, 25]             256\n             ReLU-71         [100, 128, 25, 25]               0\n           Conv2d-72         [100, 128, 25, 25]         147,456\n      BatchNorm2d-73         [100, 128, 25, 25]             256\n             ReLU-74         [100, 128, 25, 25]               0\n           Conv2d-75         [100, 512, 25, 25]          65,536\n      BatchNorm2d-76         [100, 512, 25, 25]           1,024\n             ReLU-77         [100, 512, 25, 25]               0\n       Bottleneck-78         [100, 512, 25, 25]               0\n           Conv2d-79         [100, 256, 25, 25]         131,072\n      BatchNorm2d-80         [100, 256, 25, 25]             512\n             ReLU-81         [100, 256, 25, 25]               0\n           Conv2d-82         [100, 256, 13, 13]         589,824\n      BatchNorm2d-83         [100, 256, 13, 13]             512\n             ReLU-84         [100, 256, 13, 13]               0\n           Conv2d-85        [100, 1024, 13, 13]         262,144\n      BatchNorm2d-86        [100, 1024, 13, 13]           2,048\n           Conv2d-87        [100, 1024, 13, 13]         524,288\n      BatchNorm2d-88        [100, 1024, 13, 13]           2,048\n             ReLU-89        [100, 1024, 13, 13]               0\n       Bottleneck-90        [100, 1024, 13, 13]               0\n           Conv2d-91         [100, 256, 13, 13]         262,144\n      BatchNorm2d-92         [100, 256, 13, 13]             512\n             ReLU-93         [100, 256, 13, 13]               0\n           Conv2d-94         [100, 256, 13, 13]         589,824\n      BatchNorm2d-95         [100, 256, 13, 13]             512\n             ReLU-96         [100, 256, 13, 13]               0\n           Conv2d-97        [100, 1024, 13, 13]         262,144\n      BatchNorm2d-98        [100, 1024, 13, 13]           2,048\n             ReLU-99        [100, 1024, 13, 13]               0\n      Bottleneck-100        [100, 1024, 13, 13]               0\n          Conv2d-101         [100, 256, 13, 13]         262,144\n     BatchNorm2d-102         [100, 256, 13, 13]             512\n            ReLU-103         [100, 256, 13, 13]               0\n          Conv2d-104         [100, 256, 13, 13]         589,824\n     BatchNorm2d-105         [100, 256, 13, 13]             512\n            ReLU-106         [100, 256, 13, 13]               0\n          Conv2d-107        [100, 1024, 13, 13]         262,144\n     BatchNorm2d-108        [100, 1024, 13, 13]           2,048\n            ReLU-109        [100, 1024, 13, 13]               0\n      Bottleneck-110        [100, 1024, 13, 13]               0\n          Conv2d-111         [100, 256, 13, 13]         262,144\n     BatchNorm2d-112         [100, 256, 13, 13]             512\n            ReLU-113         [100, 256, 13, 13]               0\n          Conv2d-114         [100, 256, 13, 13]         589,824\n     BatchNorm2d-115         [100, 256, 13, 13]             512\n            ReLU-116         [100, 256, 13, 13]               0\n          Conv2d-117        [100, 1024, 13, 13]         262,144\n     BatchNorm2d-118        [100, 1024, 13, 13]           2,048\n            ReLU-119        [100, 1024, 13, 13]               0\n      Bottleneck-120        [100, 1024, 13, 13]               0\n          Conv2d-121         [100, 256, 13, 13]         262,144\n     BatchNorm2d-122         [100, 256, 13, 13]             512\n            ReLU-123         [100, 256, 13, 13]               0\n          Conv2d-124         [100, 256, 13, 13]         589,824\n     BatchNorm2d-125         [100, 256, 13, 13]             512\n            ReLU-126         [100, 256, 13, 13]               0\n          Conv2d-127        [100, 1024, 13, 13]         262,144\n     BatchNorm2d-128        [100, 1024, 13, 13]           2,048\n            ReLU-129        [100, 1024, 13, 13]               0\n      Bottleneck-130        [100, 1024, 13, 13]               0\n          Conv2d-131         [100, 256, 13, 13]         262,144\n     BatchNorm2d-132         [100, 256, 13, 13]             512\n            ReLU-133         [100, 256, 13, 13]               0\n          Conv2d-134         [100, 256, 13, 13]         589,824\n     BatchNorm2d-135         [100, 256, 13, 13]             512\n            ReLU-136         [100, 256, 13, 13]               0\n          Conv2d-137        [100, 1024, 13, 13]         262,144\n     BatchNorm2d-138        [100, 1024, 13, 13]           2,048\n            ReLU-139        [100, 1024, 13, 13]               0\n      Bottleneck-140        [100, 1024, 13, 13]               0\n          Conv2d-141         [100, 512, 13, 13]         524,288\n     BatchNorm2d-142         [100, 512, 13, 13]           1,024\n            ReLU-143         [100, 512, 13, 13]               0\n          Conv2d-144           [100, 512, 7, 7]       2,359,296\n     BatchNorm2d-145           [100, 512, 7, 7]           1,024\n            ReLU-146           [100, 512, 7, 7]               0\n          Conv2d-147          [100, 2048, 7, 7]       1,048,576\n     BatchNorm2d-148          [100, 2048, 7, 7]           4,096\n          Conv2d-149          [100, 2048, 7, 7]       2,097,152\n     BatchNorm2d-150          [100, 2048, 7, 7]           4,096\n            ReLU-151          [100, 2048, 7, 7]               0\n      Bottleneck-152          [100, 2048, 7, 7]               0\n          Conv2d-153           [100, 512, 7, 7]       1,048,576\n     BatchNorm2d-154           [100, 512, 7, 7]           1,024\n            ReLU-155           [100, 512, 7, 7]               0\n          Conv2d-156           [100, 512, 7, 7]       2,359,296\n     BatchNorm2d-157           [100, 512, 7, 7]           1,024\n            ReLU-158           [100, 512, 7, 7]               0\n          Conv2d-159          [100, 2048, 7, 7]       1,048,576\n     BatchNorm2d-160          [100, 2048, 7, 7]           4,096\n            ReLU-161          [100, 2048, 7, 7]               0\n      Bottleneck-162          [100, 2048, 7, 7]               0\n          Conv2d-163           [100, 512, 7, 7]       1,048,576\n     BatchNorm2d-164           [100, 512, 7, 7]           1,024\n            ReLU-165           [100, 512, 7, 7]               0\n          Conv2d-166           [100, 512, 7, 7]       2,359,296\n     BatchNorm2d-167           [100, 512, 7, 7]           1,024\n            ReLU-168           [100, 512, 7, 7]               0\n          Conv2d-169          [100, 2048, 7, 7]       1,048,576\n     BatchNorm2d-170          [100, 2048, 7, 7]           4,096\n            ReLU-171          [100, 2048, 7, 7]               0\n      Bottleneck-172          [100, 2048, 7, 7]               0\nAdaptiveAvgPool2d-173          [100, 2048, 1, 1]               0\n          Linear-174                  [100, 29]          59,421\n================================================================\nTotal params: 23,567,453\nTrainable params: 59,421\nNon-trainable params: 23,508,032\n----------------------------------------------------------------\nInput size (MB): 45.78\nForward/backward pass size (MB): 23475.71\nParams size (MB): 89.90\nEstimated Total Size (MB): 23611.38\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Model 1\n#### Traing ResNet-50 CNN \n\n* Cost Function = CrossEntropyLoss\n* Optimizer = Adam\n* Learning Rate = 0.001","metadata":{}},{"cell_type":"markdown","source":"**Defining the Loss Function and Optimizer**","metadata":{}},{"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model_resnet.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T08:44:35.951960Z","iopub.execute_input":"2022-05-11T08:44:35.952208Z","iopub.status.idle":"2022-05-11T08:44:35.957553Z","shell.execute_reply.started":"2022-05-11T08:44:35.952175Z","shell.execute_reply":"2022-05-11T08:44:35.956739Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Training model","metadata":{}},{"cell_type":"code","source":"num_epochs = 5\nfor epoch in range(num_epochs):\n    correct = 0\n    for batch_idx , (data,labels) in enumerate(train_dataloader):\n        data = data.to(device=device)\n        labels = labels.to(device= device)\n        data, labels = data.cuda(), labels.cuda()\n        \n        #forward\n        scores = model_resnet(data)\n        loss = criterion(scores, labels)\n\n        #backprop\n        optimizer.zero_grad()\n        loss.backward()\n\n        #gradient descent\n        optimizer.step()\n        \n        #performance\n        prediction = torch.max(scores,1)[1]\n    \n        correct += (prediction == labels).cpu().sum().numpy()\n\n    print(\"Epoch :\",epoch,\"\\tLoss :\",loss.data,\"\\tAccuracy :\",(correct/len(train_dataloader.dataset))*100)        ","metadata":{"execution":{"iopub.status.busy":"2022-05-11T08:44:35.958653Z","iopub.execute_input":"2022-05-11T08:44:35.958878Z","iopub.status.idle":"2022-05-11T09:15:19.398008Z","shell.execute_reply.started":"2022-05-11T08:44:35.958849Z","shell.execute_reply":"2022-05-11T09:15:19.397150Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch : 0 \tLoss : tensor(0.4173, device='cuda:0') \tAccuracy : 82.63793103448276\nEpoch : 1 \tLoss : tensor(0.2076, device='cuda:0') \tAccuracy : 93.09195402298852\nEpoch : 2 \tLoss : tensor(0.1642, device='cuda:0') \tAccuracy : 94.6551724137931\nEpoch : 3 \tLoss : tensor(0.1466, device='cuda:0') \tAccuracy : 95.62758620689655\nEpoch : 4 \tLoss : tensor(0.0749, device='cuda:0') \tAccuracy : 96.24942528735633\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Setting up Test Dataset","metadata":{}},{"cell_type":"code","source":"test_filepath = \"../input/asl-alphabet/asl_alphabet_test/\"\n\ntest_transforms = transforms.Compose([\n    transforms.ToTensor()\n])\n\ntest_dataset = datasets.ImageFolder(test_filepath, transform=test_transforms)\nprint(\"Test Dataset Info:\\n\",test_dataset)\n\ntest_dataloader = torch.utils.data.DataLoader(dataset=test_dataset,\n                                               batch_size=1,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T10:21:11.765860Z","iopub.execute_input":"2022-05-11T10:21:11.766520Z","iopub.status.idle":"2022-05-11T10:21:11.775020Z","shell.execute_reply.started":"2022-05-11T10:21:11.766489Z","shell.execute_reply":"2022-05-11T10:21:11.774232Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Test Dataset Info:\n Dataset ImageFolder\n    Number of datapoints: 28\n    Root location: ../input/asl-alphabet/asl_alphabet_test/\n    StandardTransform\nTransform: Compose(\n               ToTensor()\n           )\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\ntest_filepath = \"../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/\"\nlabels_map = {'A':0,'B':1,'C': 2, 'D': 3, 'E':4,'F':5,'G':6, 'H': 7, 'I':8, 'J':9,'K':10,'L':11, 'M': 12, 'N': 13, 'O':14, \n                'P':15,'Q':16, 'R': 17, 'S': 18, 'T':19, 'U':20,'V':21, 'W': 22, 'X': 23, 'Y':24, 'Z':25, \n                'del': 26, 'nothing': 27,'space':28}\ntest_labels = []\nfor folder_name in os.listdir(test_filepath):\n    label = folder_name.replace(\"_test.jpg\",\"\")\n    label = labels_map[label]\n    test_labels.append(np.array(label))\ntest_labels.sort()\n    \nprint(test_labels)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T10:33:50.285551Z","iopub.execute_input":"2022-05-11T10:33:50.286250Z","iopub.status.idle":"2022-05-11T10:33:50.308413Z","shell.execute_reply.started":"2022-05-11T10:33:50.286203Z","shell.execute_reply":"2022-05-11T10:33:50.307582Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"[array(0), array(1), array(2), array(3), array(4), array(5), array(6), array(7), array(8), array(9), array(10), array(11), array(12), array(13), array(14), array(15), array(16), array(17), array(18), array(19), array(20), array(21), array(22), array(23), array(24), array(25), array(27), array(28)]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Testing ResNet-50 Model with CorssEntropy,Adam,LearningRate=0.001","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    correct = 0\n    for (images,x),labels in zip(test_dataloader,test_labels):\n        model_resnet.eval()\n        images = images.to(device)\n#         labels = labels.to(device)\n        output = model_resnet(images)\n        prediction = torch.max(output,1)[1]\n        correct += (prediction.cpu().numpy()[0] == labels)\n    print(\"Accuracy :\",(correct/len(test_dataloader.dataset))*100,\"%\")","metadata":{"execution":{"iopub.status.busy":"2022-05-11T10:38:00.677120Z","iopub.execute_input":"2022-05-11T10:38:00.677387Z","iopub.status.idle":"2022-05-11T10:38:00.957934Z","shell.execute_reply.started":"2022-05-11T10:38:00.677358Z","shell.execute_reply":"2022-05-11T10:38:00.957149Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"Accuracy : 100.0 %\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Model 2\n#### Traing ResNet-50 CNN \n\n* Cost Function = CrossEntropyLoss\n* Optimizer = SGD\n* Learning Rate = 0.001","metadata":{}},{"cell_type":"markdown","source":"**Defining the Loss Function and Optimizer**","metadata":{}},{"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\noptimizerSGD = torch.optim.SGD(model_resnet.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:26:50.389445Z","iopub.execute_input":"2022-05-11T11:26:50.389712Z","iopub.status.idle":"2022-05-11T11:26:50.396523Z","shell.execute_reply.started":"2022-05-11T11:26:50.389680Z","shell.execute_reply":"2022-05-11T11:26:50.393762Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"**Training model**","metadata":{}},{"cell_type":"code","source":"num_epochs = 5\nfor epoch in range(num_epochs):\n    correct = 0\n    for batch_idx , (data,labels) in enumerate(train_dataloader):\n        data = data.to(device=device)\n        labels = labels.to(device= device)\n        data, labels = data.cuda(), labels.cuda()\n        \n        #forward\n        scores = model_resnet(data)\n        loss = criterion(scores, labels)\n\n        #backprop\n        optimizerSGD.zero_grad()\n        loss.backward()\n\n        #gradient descent\n        optimizer.step()\n        \n        #performance\n        prediction = torch.max(scores,1)[1]\n    \n        correct += (prediction == labels).cpu().sum().numpy()\n\n    print(\"Epoch :\",epoch,\"\\tLoss :\",loss.data,\"\\tAccuracy :\",(correct/len(train_dataloader.dataset))*100)        ","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:26:52.181928Z","iopub.execute_input":"2022-05-11T11:26:52.182249Z","iopub.status.idle":"2022-05-11T11:54:15.063389Z","shell.execute_reply.started":"2022-05-11T11:26:52.182219Z","shell.execute_reply":"2022-05-11T11:54:15.062622Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"Epoch : 0 \tLoss : tensor(0.0708, device='cuda:0') \tAccuracy : 97.73103448275862\nEpoch : 1 \tLoss : tensor(0.0836, device='cuda:0') \tAccuracy : 97.81954022988506\nEpoch : 2 \tLoss : tensor(0.0874, device='cuda:0') \tAccuracy : 97.81724137931035\nEpoch : 3 \tLoss : tensor(0.0655, device='cuda:0') \tAccuracy : 97.82988505747127\nEpoch : 4 \tLoss : tensor(0.1210, device='cuda:0') \tAccuracy : 97.84137931034482\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Testing ResNet-50 Model with CorssEntropy,SGD,LearningRate=0.001","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    correct = 0\n    pred_list =[]\n    for (images,x),labels in zip(test_dataloader,test_labels):\n        model_resnet.eval()\n        images = images.to(device)\n#         labels = labels.to(device)\n        output = model_resnet(images)\n        prediction = torch.max(output,1)[1]\n        pred_list.append(prediction.cpu().numpy()[0])\n        correct += (prediction.cpu().numpy()[0] == labels)\n    print(\"Accuracy :\",(correct/len(test_dataloader.dataset))*100,\"%\")","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:57:51.846485Z","iopub.execute_input":"2022-05-11T11:57:51.846759Z","iopub.status.idle":"2022-05-11T11:57:52.127224Z","shell.execute_reply.started":"2022-05-11T11:57:51.846730Z","shell.execute_reply":"2022-05-11T11:57:52.126497Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"Accuracy : 100.0 %\n","output_type":"stream"}]}]}